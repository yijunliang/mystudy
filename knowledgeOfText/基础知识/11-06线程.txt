1、创建线程的方式有多少种
   1>继承自Thread类，重写run方法
   2>实现Runnable接口，重写run方法
   3>实现Callable接口,重写call方法
    （可以在任务结束后提供返回一个值
      call方法可以抛出异常，run方法不能
      运行Callable可以拿到一个Future对象）


2、线程的状态，初始化、就绪、运行、阻塞、结束
   线程start之后不是马上进入执行状态，而是进入就绪状态等待cpu调度


3、什么是线程
   线程是能够执行程序代码的一个执行单元。
   

4、多线程的好处
   1>减少程序响应时间
   2>线程的创建以及切换消耗的系统资源比进程小
   3>简化程序结构，是程序便于理解与维护
   4>计算机本身就具有执行多线程的能力，如果只使用单线程是很大的浪费


5、同步和异步的区别
   同步:当请求处理某件事时，必须要等待返回结果，才能继续执行下一步操作。
   异步:请求某件事时，不必等待返回结果，就可以继续执行别的操作。


6、实现多线程同步的方法有哪些
   1>使用synchronized关键字（synchronized块，synchronized方法）
   2>wait()、notify()，一定要在synchronized块或方法中
   3>Lock接口，实现类ReentrantLock主要方法
     lock()以阻塞的方式获取锁
     tryLock()以非阻塞的方式获取锁
     lockInterruptibly()如果获取了锁就立即返回，否则处于休眠状态直到获取到锁，如果被中断会收到中断异常
   4>设置标志，线程访问，查看标志如果是为假即证名没有别的线程在访问那么就访问，把标志改为真，访问结束
     再把标志改回为假。


7、sleep()和wait()方法的区别
   1>sleep不会释放对象锁，而wait会释放对象锁
   2>sleep是Thread类的静态方法，而wait是Object类的方法
   3>sleep可以在任何地方使用，而wait只能在同步块或同步方法中使用
   4>sleep必须捕获异常，而wait不用捕获异常


8、什么是守护线程，特点
   1>守护线程是程序在运行时在后台提供一种通用服务的线程
   2>如果没有任何用户线程在执行，程序就结束了（即使有守护线程）
     换言之只要有任何非守护线程存在程序就不会结束
   3>创建守护线程的方式在线程start之前t1.setDaemom(true);

9、join方法的作用
   1>将两个线程合并，用于实现同步功能。
   2>a.join()就是把a线程加入到正在执行线程中去，正在执行的线程等待a线程的执行结束再继续执行。



10、死锁的编程实现

package com.yjl.deadlock;
//死锁的演示
public class DeadLock extends Thread {
	//a资源
	private int a = 1;
	private static Object o1 = new Object();
	private static Object o2 = new Object();
	public void run() {
		System.out.println("a=" + a);
	    if(a == 1) {
	    	synchronized(o1) {
	    		try {
	    			System.out.println("拿到了o1资源");
					Thread.sleep(1000);
				} catch (InterruptedException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
	    		synchronized(o2) {
	    			System.out.println("拿到了o1资源也拿到了o2资源");
	    		}
	    	}
	    }
	    if(a == 0) {
	    	synchronized(o2) {
	    		try {
	    			System.out.println("拿到了o2资源");
					Thread.sleep(1000);
				} catch (InterruptedException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
	    		synchronized(o1) {
	    			System.out.println("拿到了o2资源也拿到了o1资源");
	    		}
	    	}
	    }
	}
	
	public static void main(String[] args) {
		DeadLock deadLock1 = new DeadLock();
		DeadLock deadLock2 = new DeadLock();
		deadLock1.a = 1;
		deadLock2.a = 0;
		deadLock1.start();
		deadLock2.start();
	}
}


11、生产者消费者的编程实现


12、线程之间是如何通信的
    1>通过共享内存区域，synchronized关键字
	2>while轮询的方式，线程不停地通过while语句检测这个条件(list.size()==5)是否成立 ，从而实现了线程间的通信。
	3>wait/notify机制
	4>管道通信就是使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信
	
13、线程池工作原理

14、一个web请求是一个线程吗？
    一个http请求，就是一个线程，Tomcat会维护一个线程池


15、Tomcat是如何处理http请求的？
    对tomcat来说，每一个进来的请求(request)都需要一个线程，直到该请求结束。
	如果同时进来的请求多于当前可用的请求处理线程数，额外的线程就会被创建，直到到达配置的最大线程数(maxThreads属性值)。
	如果仍就同时接收到更多请求，这些来不及处理的请求就会在Connector创建的ServerSocket中堆积起来，直到到达最大的配置值(acceptCount属性值)。
	至此，任何再来的请求将会收到connection refused错误，直到有可用的资源来处理它们。实现达到Tomcat的最大连接数然后抛出错误。
	
	tomcat的http connector有三种：bio、nio、apr。
	查阅http://tomcat.apache.org/tomcat-7.0-doc/config/http.html配置文档Connector Comparison部分便可获知各种connector实现间的差异。
	怎样才能知道容器使用的是何种connector实现？启动tomcat后，访问Server Status Page，看到如下信息即可知道使用的是何种connector
	
	OS是windows，所以tomcat默认使用的是aprconnector。在linux上，默认使用的是bio connector。与nio相比，bio性能较低。
	
	Bio模式
	    bio(blocking I/O)是指阻塞式I/O操作，Tomcat在默认情况下就是以bio模式运行的。这可以从守护线程的信息看出来。
		
		bio缺点：1.当客户端多时，会创建大量的处理线程。每个线程都要占用栈空间和一些CPU时间。 
                 2.阻塞可能带来频繁的上下文切换，而大部分的上下文切换是无意义的。
	
	Nio模式
		要让Tomcat以nio模式来运行也比较简单，我们只需要修改下server.xml文件：
		<Connector port="8080" protocol="HTTP/1.1" 
				   connectionTimeout="20000" 
				   redirectPort="8443" />
		改为-->
		<Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol" 
				   connectionTimeout="20000" 
				   redirectPort="8443" />
				   
	    NIO的工作原理包括： 
		1.由一个专门的线程来处理所有的 I/O 事件、并负责分发。 
		2.事件驱动机制，而不再同步地去监视事件。 
		3.线程之间通过 wait,notify 等方式通讯。保证每次上下文切换都是有意义的，减少无谓的线程切换
		NIO采用了双向通道(channel)进行数据传输，而不是单向的流(stream)。
		
	Apr模式		   
		apr(Apache portable Run-time libraries/Apache可移植运行库)是Apache HTTP服务器的支持库。
		在apr模式下，Tomcat将以JNI(Java Native Interface)的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，
		从而大大提高Tomcat对静态文件的处理性能。Tomcat apr是在Tomcat上运行高并发应用的首选模式。
		而要让Tomcat以apr模式运行，对于Tomcat 7.0.30开始向后的版本，只需要再次修改protocol为”org.apache.coyote.http11.Http11AprProtocol”即可。
		
16、NIO和BIO的原理及优缺点

17、如何加大tomcat连接数
	在tomcat配置文件server.xml中的<Connector />配置中，和连接数相关的参数有：
	minProcessors：最小空闲连接线程数，用于提高系统处理性能，默认值为10
	maxProcessors：最大连接线程数，即：并发处理的最大请求数，默认值为75
	acceptCount：允许的最大连接数，应大于等于maxProcessors，默认值为100
	enableLookups：是否反查域名，取值为：true或false。为了提高处理能力，应设置为false
	connectionTimeout：网络连接超时，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。
	其中和最大连接数相关的参数为maxProcessors和acceptCount。如果要加大并发连接数，应同时加大这两个参数。
	web server允许的最大连接数还受制于操作系统的内核参数设置，通常Windows是2000个左右，Linux是1000个左右。tomcat5中的配置示例：
		<Connector port="8080"
				  maxThreads="150" minSpareThreads="25"maxSpareThreads="75"
				  enableLookups="false" redirectPort="8443"acceptCount="100"
				  debug="0" connectionTimeout="20000" 
				  disableUploadTimeout="true" />
	对于其他端口的侦听配置，以此类推。
	
18、如何加大tomcat可以使用的内存
	tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的，需要调大。
	Unix下，在文件{tomcat_home}/bin/catalina.sh的前面，增加如下设置：
	JAVA_OPTS='-Xms【初始化内存大小】 -Xmx【可以使用的最大内存】'
	需要把这个两个参数值调大。例如：
	JAVA_OPTS='-Xms256m -Xmx512m'
	表示初始化内存为256MB，可以使用的最大内存为512MB

19、如何开始一个http请求
    1>http请求和响应步骤：
		1)建立TCP连接(TCP三次握手)。
		2)web浏览器向web服务器发送请求命令，如GET/sample/hello.jsp HTTP/1.1。
		3)web浏览器发送请求头信息，如user-agent,host等关于自身的信息，最后发送一个空请求头代表请求头信息发送完毕。
		  如果是post提价会继续提交请求体。服务器收到请求后，实例化servlet对象(只会实例化一次)，以后的每次请求都是复用第一次实例化的servlet对象，
		  servlet对象调用service方法处理请求，如果有多个请求要处理，则会创建多线程处理即多线程调用servlet.service()。
		4)web服务器应答，应答第一部分是版本号和协议状态码 HTTP/1.1 200 ok。
		5)web服务发送应答头信息，关于自己的信息及被请求的文档，最后发送一个空白行代表头信息发送结束。
		6)web服务器向浏览器发送数据，以Context-Type应答头信息所描述的格式发送用户所请求的实际数据。
		7)web服务器关闭TCP连接，一旦web服务器向浏览器发送了请求数据就需要关闭tcp连接(无状态连接)。如果添加connection:keep-alive将不会关闭TCP连接。
	2>TCP三次握手：
	    TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接，通过三次握手进行TCP连接的初始化。
		第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；
		第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；
		            同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，
					一并发送给客户端，此时服务器进入SYN_RECV状态；
		第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，
		            这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。
	3>为什么要三次握手：
      为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。具体例子:
	  client发出的第一个连接请求报文段由于网络原因，延迟到达server(失效的连接请求)，server接收到该失效连接请求后误认为是client发出的新的连接请求，
	  于是向client发出确认报文段，同意建立连接，如果不用三次握手，那么只要server发出确认新的连接就建立了。但是由于client实际上没有发出新的连接请求，
	  所以不会向server送数据，而server却一直在等client发送数据，这样就造成了server资源的浪费。使用三次握手就不会有这个问题。
	  
	4>TCP关闭连接的四次挥手：
	第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；
				这表示主机1没有数据要发送给主机2了；
	第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；
				主机2告诉主机1，我“同意”你的关闭请求；
	第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；
	第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；
				此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。
	  
20、什么是http
    http是计算机通过网络进行通信的规则，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据。
	请求与响应：客户端发送请求，服务器端响应数据。
	无状态的：协议对于事务处理没有记忆能力，客户端第一次与服务器建立连接发送请求时需要进行一系列的安全认证匹配等，
	          因此增加页面等待时间，当客户端向服务器端发送请求，服务器端响应完毕后，两者断开连接，也不保存连接状态，一刀两断！恩断义绝！从此路人！
			  下一次客户端向同样的服务器发送请求时，由于他们之前已经遗忘了彼此，所以需要重新建立连接。
	应用层：Http是属于应用层的协议，配合TCP/IP使用。
    TCP/IP：Http使用TCP作为它的支撑运输协议。HTTP客户机发起一个与服务器的TCP连接，一旦连接建立，浏览器（客户机）和服务器进程就可以通过套接字接口访问TCP。
	
21、针对http无状态的一些解决策略
    有时需要对用户之前的HTTP通信状态进行保存，比如执行一次登陆操作，在30分钟内所有的请求都不需要再次登陆。于是引入了Cookie技术。
	HTTP/1.1想出了持久连接（HTTP keep-alive）方法。其特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态，
	在请求首部字段中的Connection: keep-alive即为表明使用了持久连接。
	
22、一个http请求什么时候断开连接
    http协议，只要response回来了，这次连接就断开了。这里不能使用多线程。
	
23、什么是短连接和长连接
    长连接：client方与server方先建立连接，连接建立后不断开，然后再进行报文发送和接收。这种方式下由于通讯连接一直存在。此种方式常用于P2P点对点的通信。
    长连接的操作步骤是：建立连接――数据传输...（保持连接）...数据传输――关闭连接
	长连接适用场景：监控系统：后台硬件热插拔、LED、温度、电压发生变化；
                    即时通信系统：其它用户登录、发送信息；
					即时报价系统：后台数据库内容发生变化；
					像以上这些连接，如果每次操作都要建立连接然后再操作的话处理速度会降低。
					所以操作时第一次连接上以后，以后每次直接发送数据就可以了，不用再建立TCP连接。
					再比如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket错误，频繁的socket创建也是对资源的浪费。
					
	短连接：Client方与server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此方式常用于一点对多点通讯。
    短连接的操作步骤是：建立连接――数据传输――关闭连接...建立连接――数据传输――关闭连接。
	短连接的适用场景：短连接多用于操作频繁，点对点的通讯，而且连接数不能太多的情况。每个TCP连接的建立都需要三次握手，每个TCP连接的断开要四次握手。
	                  web网站的http服务一般都用短连接。因为长连接对于服务器来说要耗费一定的资源。
					  像web网站这么频繁的成千上万甚至上亿客户端的连接用短连接更省一些资源。试想如果都用长连接，而且同时用成千上万的用户，
					  每个用户都占有一个连接的话，可想而知服务器的压力有多大。所以并发量大，但是每个用户又不需频繁操作的情况下需要短连接。
					  总之：长连接和短连接的选择要视需求而定。

					
24、Comet
以前的http的长连接技术不成熟，目前有新技术名叫Comet：基于 HTTP 长连接的“服务器推”技术。
案例：基于 AJAX 的长轮询（long-polling）方式
AJAX 的出现使得 JavaScript 可以调用 XMLHttpRequest 对象发出 HTTP 请求，JavaScript 响应处理函数根据服务器返回的信息对 HTML 页面的显示进行更新。
使用 AJAX 实现“服务器推”与传统的 AJAX 应用不同之处在于执行顺序及内容：
1.服务器端会阻塞请求直到有数据传递或超时才返回。
2.客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。
3.当客户端处理接收的数据、重新建立连接时，服务器端可能有新的数据到达；这些信息会被服务器端保存直到客户端重新建立连接，客户端会一次把当前服务器端所有的信息取回。


25、http请求头报文常见名词解释


26、http响应头部常见名词解释


27、servlet天生具有多线程性
    servlet是单例的，是线程不安全的，即controller类实例是线程不安全的。
	当Tomcat接收到Client的HTTP请求时，Tomcat从线程池中取出一个线程，之后找到该请求对应的Servlet对象并进行初始化，之后调用service()方法。
	要注意的是每一个Servlet对象再Tomcat容器中只有一个实例对象，即是单例模式。
	
28、什么是servlet
    servlet的本质其实也是一个java bean，controller是对servlet的封装，底层依旧是servlet。
	servlet是单例的，浏览器请求服务器时，服务器会根据浏览器传过来的请求路径，如果是第一次请求则实例化servlet，然后调用service方法处理请求，
	否则复用已存在的servlet实例，调用service方法处理请求，在服务器的整个生命周期中该servlet单实例是一直存在的。服务器关闭时销毁。
	每个个servlet类只会有一个实例，如AServlet、BServlet在服务器(Tomcat)整个生命周期只会有一个AServlet和一个BServlet实例。
	
29、springboot中controller类默认是在容器启动时实例化的，只会实例化一次。也就是说有多少个不同的controller类就会实例化多少个不同的controller类实例。
    但是dispatcherServlet是请求第一到来是实例化的，如
	Initializing Spring FrameworkServlet 'dispatcherServlet'。
	FrameworkServlet 'dispatcherServlet': initialization started。
	FrameworkServlet 'dispatcherServlet': initialization completed in 47 ms。
	
30、线程之间的协作(线程之间的通信)
    1>wait()与notifyAll()
	  wait()在等待外部条件发生变化的时候会将任务挂起，只有在notify()或notifyAll()发生时，这个任务才回被唤醒并去检查所产生的变化。
	  反之，如果使用循环一直对某个条件进行检测(空循环)，这就是忙等待，非常浪费cpu资源。
	  
	2>notifyAll()不是唤醒程序中所有的在等待的任务，而是唤醒因调用notifyAll()的对象所在锁而阻塞的所有任务。如：
	  线程A、线程B因对象obj而wait()，而线程C因obj1而wait()，在obj中调用notifyAll()只会唤醒线程A、线程B。
	
31、线程机制
    1>并发编程可以将程序划分为多个分离的、独立运行的任务。每一个独立的任务由执行它的线程来驱动。底层机制是切分cpu时间(把CPU时间轮流分给线程)。
	
	
32、synchronized关键字
    当任务要执行被synchronized保护的资源时，它将检查锁是否可用，获取锁，执行任务代码，释放锁。
	多线程对同一个实例(对象)的同步方法的访问会阻塞，即对访问synchronizedTest的对象锁会阻塞。
	多线程对多个实例的synchronized方法不会阻塞，只会阻塞各自的实例(对象)锁。
	synchronized锁住的是同一对象的锁，而不是类的锁，一个类可以new多个实例对象。如果类中一个synchronized
	调用一个非synchronized方法，这个非synchronized方法会等待，别的线程能不能访问到这个非synchronized方法呢？
	非synchronized方法不会阻塞，也就是访问非synchronized方法不需要检查锁是否可用。
	但是如果非synchronized方法变为synchronized那么则会获得两次对象锁，只要当这两个对象锁都释放的时候别的线程才能获取到这个对象的资源。
	通俗地说就是每当任务进入一个synchronized方法时获得锁的计数就增加一，每当离开一个synchronized方法时，锁计数减一，当计数为零时就释放对象锁。
	
	synchronized块，锁定的是某个对象实例，比锁定整个方法高效。
	
33、volatile关键字作用
    1>让修改立即可见，修改状态之后，立即同步到主存中，而别的线程读取数据都是从主存中拷贝一份副本。
	
34、防止任务在共享资源上产生冲突的方式
    1>使用synchronized关键字
	2>去掉共享变量
	
35、java内存模型(线程内存模型)

36、本地线程(ThreadLocal)
    1、使用本地线程可以去除掉共享变量。
	2、ThreadLocal可以让原本的static全局静态变量变为每个线程都有一份，从而避免资源竞争。
	3、ThreadLocal的实现原理：
	每个Thread的对象都有一个内部类ThreadLocalMap，当创建一个ThreadLocal的时候，就会将该ThreadLocal对象添加到该Map中，
	其中键就是ThreadLocal，值可以是任意类型。
    在该类中，我觉得最重要的方法就是两个：set()和get()方法。当调用ThreadLocal的get()方法的时候，
	会先找到当前线程的ThreadLocalMap，然后再找到对应的值。set()方法也是一样。
	
37、线程状态
    1>新建
	2>就绪
	3>运行
	4>阻塞：进入阻塞状态原因，sleep、wait、等待输入/输出、对象锁已经被别的线程获取。
	5>死亡
	
38、线程上下文切换和进程上下文切换
    1>一个给定进程内的所有线程共享相同的内存空间，线程的上下文切换只是改变了程序的执行序列和局部变量；
	  而进程切换需要改变所有内存空间。
	  
39、生产者和消费者


40、http的post请求的参数是放在那里
    HTTP 协议是以 ASCII 码 传输，建立在 TCP/IP 协议之上的应用层规范。规范把 HTTP 请求分为三个部分：状态行、请求头、消息主体。
    协议规定 POST 提交的数据必须放在消息主体（entity-body）中，但协议并没有规定数据必须 使用什么编码方式 。
	而post请求方式的参数是在request body中。
	
	1>application/x-www-form-urlencoded(content-type)
      浏览器的原生 <form> 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据。
	  
	2>multipart/form-data(content-type)
	  用来上传文件。
	  
	3>application/json(content-type)
	  以json字符串的形式存在于消息主体，获取参数方法：
	  1)@RequestBody User user通过对象获取
	  2)@RequestBody Map<String, Object> map 通过map获取
	  3)HTTP协议将参数转换为JSONObject,JSONObject jsonObject = handlerData(request);
	
	4>text/xml(content-type)
	
41、浏览器发起一个请求到Tomcat处理请求的一个过程
    1>浏览器和服务器通过tcp三次握手建立连接,
	  第一次握手，
	  第二次握手，
	  第三次握手，
	2>向服务器发送请求数据
	  请求头，请求地址、方式等
	  消息主体，传递参数等消息
	  状态行，
	3>服务器把请求转发给指定的servlet
	4>指定servlet如果没有实例化那么就先实例化servlet(整个服务器的生命周期只会实例化一次，单例)
	5>从线程池中取出一个空闲线程，调用service方法处理该请求(dopost、doget)，如果继续有请求到来，那么继续从线程池中取出线程调用service方法处理
	6>请求处理完把结果返回给服务器，服务器把结果封装至response对象中返回给浏览器。
	7>浏览器接收到返回结果，如果没开启长连接开关，那么就关闭连接(TCP四次挥手)
	
	疑问：
	一个http请求建立tcp连接之后，可以发送多少个请求？每个请求的参数、地址等都不一样是使用相同的线程处理吗？
	可以发送多个请求，tcp连接是复用的(keep-alive属性)，也就是说，如果在浏览器输入一个页面地址，这个页面中使用了多个ajax向同一个服务器请求数据
	那么只会建立一次tcp连接，所有的ajax请求都是复用这一个tcp连接。请求完，等待一定时间，断开tcp连接，此时如果再要向服务器请求数据那么就要重新
	进行tcp三次握手建立tcp连接。
	请求的参数等信息跟tcp连接没关系，每个请求的请求头，消息主体，状态行都是独立的，即使使用同一个tcp连接也不会相互影响。
	如果多个ajax向多个不同服务器请求数据，那么应该要建立服务器数量个tcp连接。
	
	长连接：适合那些需要频繁通信的应用，连接数不能太多情况。如心跳检测，每30秒发送一次心跳请求，如果使用短连接，
	        将会频繁的建立，断开tcp连接，浪费资源，效率不高。数据库的连接也是使用长连接。
	
	短连接：WEB网站的http服务一般都用短链接，并发量大用短连接（错误观点）。目前http1.1，默认都是使用长连接，每一个web请求，都会伴随着图片，
	        js，css，html等资源的请求，所以使用长连接，就不用每次都建立tcp连接。
	
	
	
	以上描述都理解错误了，http是基于请求/响应模式的，没有长短连接一说，是无状态的。
	http协议是应用层协议，tcp是传输层协议，tcp采用长短连接一说。
	通俗地说，短连接是：http请求1-->建立tcp连接A-->传输数据-->响应数据，http请求1结束。
	                    http请求2-->建立tcp连接B-->传输数据-->响应数据，http请求2结束。
						http请求n-->建立tcp连接n-->传输数据-->响应数据，http请求n结束。
	
	所谓的长连接其实是：http请求1-->建立tcp连接A-->传输数据-->响应数据，http请求1结束。
	                    http请求2-->复用tcp连接A-->传输数据-->响应数据，http请求2结束。
						http请求n-->复用tcp连接A-->传输数据-->响应数据，http请求n结束。
						
	关于以上模型疑问：
	
	    一个web请求，伴随的js、html、css、图片的资源请求是属于这个web请求吗？
		
		两个web请求，A和B。A和B都伴随着js、html、css、图片的资源请求，此时A和B跟各自的js、html、css、图片等都复用同一个tcp连接，
		但是A和B是使用的通一个TCP连接吗？
		设想，A和B可能是使用的同一个TCP连接，也有可能是不同的TCP连接。如果A和B同时发起请求，A建立的TCP连接处于忙碌过程，
		那么服务器应该会再建立一个tcp连接以传输B的请求数据；如果A建立的tcp连接立马处理完A的传输数据任务，处于空闲状态，那么就会复用A的TCP连接。
						
	    
		一个Tomcat能接受的tcp连接是无限的吗？
		
		一个tcp连接能发送的请求又是无限的吗? tcp只是运输数据
		
		一个用户建立一个tcp连接还是所有的用户复用相同的tcp连接?
		
42、一台服务器的最大并发数是指http请求数，还是指tcp连接数？


43、测试一个tomcat的最大http请求数，tcp连接数
    测试1：设置最大线程数和最大连接数
			#最大线程数
			server.tomcat.max-threads=2
			#最大连接数
			server.tomcat.max-connections=3
		    浏览器打开4个窗口，访问同一个服务，处理逻辑如下：
			@RequestMapping(value="/testHttp",method=RequestMethod.GET)
			@ResponseBody
			public Object testHttp(@RequestParam Map<String,Object> map) {
				String msg = (String) map.get("msg");
				try {
					Thread.sleep(10000);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				return "返回信息：" + msg;
			}
	结果： 4个请求都有数据返回，与一个请求被拒绝的设想不符合。原因，第4个请求被放到请求队列中去，当有线程空闲时处理。
	
	测试2：	测试1的基础上增加设置请求队列大小。配置如下：
			#最大线程数，处理请求的最大线程数
			server.tomcat.max-threads=2
			#最大连接数，能同时处理请求的数量
			server.tomcat.max-connections=2
			#请求队列大小，到达最大连接数之后，请求队列能存放的请求数量，继续多出的请求将直接被拒绝
			server.tomcat.acceptCount = 1
	结果：  2个请求返回时间差不多，一个请求返回时间多一倍，一个请求被拒绝，被拒绝的请求在前面几个请求响应回来之后，又能继续请求成功(重试机制)。
	
	测试3： 在代码中设置response关闭tcp连接(变为短连接，默认长连接)，如response.setHeader("Connection", "close");
	
	结果：  浏览器返回页面中的response header中的Connection属性为close。timing中会有Initial connection属性项，即建立tcp花费的时间。
	        长连接的第一个请求，也不会显示Initial connection属性项。
			tcp连接不断开占用的话，访问用户过多会导致服务器tcp端口堵塞，无法访问的情况。
			对服务器来说, 只使用一个端口号, 不受端口号的影响.
            不过这么大的连接数, 如果只是把链接保持在那里, 或许没什么影响. 
			如果真的有那么多的用户同时使用, 就算每个用户只要 1k 的带宽, 算下来也要 800 多兆了. 
			CPU 和内存也会很难承受. 这时肯定是要分布式的多台服务器同时服务才行
	
44、Chrome浏览器中的timing各项值的意义
    Queueing
	请求文件顺序的的排序，
	浏览器有线程限制的，发请求也不能所有的请求同时发送，所以，队列喽。 
	从添加到待处理队列，到实际开始处理的时间间隔标示

	Stalled
	是浏览器得到要发出这个请求的指令到请求可以发出的等待时间，一般是代理协商、以及等待可复用的TCP连接释放的时间，
	不包括DNS查询、建立TCP连接等时间等

	DNS Lookup 
	时间执行DNS查找。每个新域pagerequires DNS查找一个完整的往返。 DNS查询的时间，当本地DNS缓存没有的时候，这个时间可能是有一段长度的，
	但是比如你一旦在host中设置了DNS，或者第二次访问，由于浏览器的DNS缓存还在，这个时间就为0了。

	Initial connection
	建立TCP连接的时间，就相当于客户端从发请求开始到TCP握手结束这一段，包括DNS查询+Proxy时间+TCP握手时间。

	Request sent 
	请求第一个字节发出前到最后一个字节发出后的时间，也就是上传时间

	Waiting(TTFB)
	请求发出后，到收到响应的第一个字节所花费的时间(Time To First Byte),发送请求完毕到接收请求开始的时间;
	这个时间段就代表服务器处理和返回数据网络延时时间了。服务器优化的目的就是要让这个时间段尽可能短。

	Content Download 
	收到响应的第一个字节，到接受完最后一个字节的时间，就是下载时间
	
45、在基于tcp的?rcp实现方式中，有如下几种选择：

	1. 长连接：同步和异步方式。

		同步方式下客户端所有请求共用同一连接，在获得连接后要对连接加锁，在读写结束后才解锁释放连接，性能低下，基本很少采用，
		唯一优点是实现极其简单。

		异步方式下所有请求都带有消息ID，因此可以批量发送请求，异步接收回复，所有请求和回复的消息都共享同一连接，
		信道得到最大化利用，因此吞吐量最大。

		这个时候接收端的处理能力也要求比较高，一般都是独立的一个（或者多个）收包线程（或者进程）防止内核缓冲区被填满影响网络吞吐量。
		缺点是实现复杂，需要异步状态机，需要增加负载均衡和连接健康度检测机制，等等。

	2. 短连接：同步方式。

		优点是实现简单，每个请求单独建立一个连接，用完即关。缺点是大量并发下会出现大量TIMEWAIT状态，信道处于过载状态，无法创建新连接。

	3. 连接池：同步方式

		每个请求单独占用一个连接，使用完以后把连接放回池中，给下一个请求使用。缺点还是网络利用率不高，因为在等待对端回复的时候，连接是空闲的

46、如果controller类中的方法加上synchronized进行同步，然后让这个方法阻塞(等待很久)，别的请求会怎样？
    别的请求会阻塞，一直等到获取锁的请求(线程)释放锁(执行完synchronized方法)。所以controller是单例的，所有的请求访问的都是同一个实例对象，
	如果该实例对象的锁被获取并阻塞将导致所有的请求阻塞。同时controller也是多线程的，有一个请求到来，就会从线程池中取一条空闲线程处理
	该请求任务。
	
47、Tomcat中的几个参数
    1、acceptCount
	accept队列的长度；当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。
	
	2、maxConnections
	Tomcat在任意时刻接收和处理的最大连接数。当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；
	这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。
	默认值与连接器使用的协议有关：NIO的默认值是10000，APR/native的默认值是8192，
	而BIO的默认值为maxThreads（如果配置了Executor，则默认值是Executor的maxThreads）。
	在windows下，APR/native的maxConnections值会自动调整为设置值以下最大的1024的整数倍；如设置为2000，则最大值实际是1024。
	
	3、maxThreads
	请求处理线程的最大数量。默认值是200（Tomcat7和8都是的）。如果该Connector绑定了Executor，这个值会被忽略，
	因为该Connector将使用绑定的Executor，而不是内置的线程池来执行任务。
	maxThreads规定的是最大的线程数目，并不是实际running的CPU数量；实际上，maxThreads的大小比CPU核心数量要大得多。
	这是因为，处理请求的线程真正用于计算的时间可能很少，大多数时间可能在阻塞，如等待数据库返回数据、等待硬盘读写数据等。
	因此，在某一时刻，只有少数的线程真正的在使用物理CPU，大多数线程都在等待；因此线程数远大于物理核心数才是合理的。
	换句话说，Tomcat通过使用比CPU核心数量多得多的线程数，可以使CPU忙碌起来，大大提高CPU的利用率。

	       
